{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import section\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping algorithm\n",
    "\n",
    "# Search limits\n",
    "min_bedrooms = 1\n",
    "max_bedrooms = 5\n",
    "min_price = 50000\n",
    "max_price = 5000000\n",
    "\n",
    "# Number of pages to retrieve. On each page there are 25 properties and non more than 42 pages are available for each request\n",
    "# even if the number of properties > 25 * 42. Before setting this parameter is important to check on the website how many pages\n",
    "# will be produced with the same query settings. If the count is more than 25 * 42 is convenient to narrow the search parameters.\n",
    "num_pages = 3 \n",
    "\n",
    "# Set initial url part\n",
    "url_str1 = 'https://www.rightmove.co.uk/property-for-sale/find.html?' # Search API link\n",
    "\n",
    "# Set following url part representing location identifier, change the uncomment code to change the location\n",
    "url_str2 = 'locationIdentifier=REGION%5E93962' # Set Hounslow\n",
    "#url_str2 = 'locationIdentifier=REGION%5E87490' # Set london area\n",
    "#url_str2 = 'locationIdentifier=REGION%5E61228' # Set Havering\n",
    "#url_str2 = 'locationIdentifier=REGION%5E61537' # Set Redbridge\n",
    "#url_str2 = 'locationIdentifier=REGION%5E93944' # Set Croydon\n",
    "#url_str2 = 'locationIdentifier=REGION%5E93974' # Set Sutton\n",
    "\n",
    "# Set the following url parts representing other query options\n",
    "url_str3 = '&propertyTypes=bungalow%2Cdetached%2Cflat%2Csemi-detached%2Cterraced' # Set property type\n",
    "url_str4 = '&includeSSTC=false&mustHave=newHome&dontShow=sharedOwnership' # Set new house and shared ownership\n",
    "url_str5 = '&minBedrooms={}&maxBedrooms={}&minPrice={}&maxPrice={}&index={}&sortType=1' # Set search parameters and page\n",
    "\n",
    "# Set path and file name \n",
    "json_file_path = 'json/'\n",
    "json_file_name = 'hounslow'\n",
    "\n",
    "# Web scraping alghoritm\n",
    "url = url_str1 + url_str2 + url_str3 + url_str4 + url_str5\n",
    "json_file = json_file_path + json_file_name + '_{}-{}_{}-{}_{}.json' # min and max bedrooms and prices are added at the end of filename.\n",
    "\n",
    "# The algorithm that generate the json files using the latest Beautiful Soup library\n",
    "for i in range(num_pages):\n",
    "    index = i * 24\n",
    "    result = requests.get(url.format(min_bedrooms, max_bedrooms, min_price, max_price, index))\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    scripts = soup.find_all('script')\n",
    "    json_str = str(scripts[4].string).replace('window.jsonModel = ','')\n",
    "    file = open(json_file.format(min_bedrooms, max_bedrooms, min_price, max_price, i), 'w', encoding=\"utf-8\")\n",
    "    file.write(json_str)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
